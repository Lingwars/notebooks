{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordNet\n",
    "\n",
    " * [Synsets](#Synsets)\n",
    "    * [Lemma](#Lemma)\n",
    " * [Relaciones](#Relaciones)\n",
    " * [Métricas](#Métricas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# Import some helpful classes and functions\n",
    "from IPython.display import HTML, display, Image\n",
    "\n",
    "def display_table(data, headers=None, caption=None):\n",
    "    html = [\"<table align=\\\"left\\\">\"]\n",
    "    \n",
    "    if caption:\n",
    "        html += [\"<caption>{}</caption>\".format(caption)]\n",
    "        \n",
    "    if headers:\n",
    "        html += [\"<tr>\"] + [\"<th>{}</th>\".format(h) for h in headers] + [\"</tr>\"]\n",
    "    \n",
    "    for row in data:\n",
    "        html += [\"<tr>\"]\n",
    "        html += [\"<td>{}</td>\".format(it) for it in row]\n",
    "        html += [\"</tr>\"]\n",
    "\n",
    "    html.append(\"</table>\")\n",
    "    display(HTML(''.join(html)))    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qué es WordNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[WordNet](https://wordnet.princeton.edu/) es una red de conceptos que contiene información codificada manualmente sobre sustantivos, verbos, adjetivos y adverbios en inglés; los términos que representan un mismo concepto están agrupados en *synsets* y son estos elementos los que constituyen los nodos de la red.\n",
    "\n",
    "WordNet se creó en el Laboratorio de Ciencia Cognitiva de la Universidad de Princeton en 1985 bajo la dirección del profesor de psicología George Armitage Miller (1920-2012)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synsets\n",
    "\n",
    "Un synset es un conjunto de palabras de la misma categoría gramatical que hacen referencia a la misma realidad extralingüística y por lo tanto pueden ser intercambiadas en un texto sin afectar al significado. Son elementos semánticamente equivalentes. Así, ocurrirá que las palabras polisémicas aparecerán múltiples veces en *synsets* diferentes.\n",
    "\n",
    "Podemos hacer una búsqueda de uno de estos *synsets* utilizando la función `synsets`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8 synsets referring to this word:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table align=\"left\"><tr><th>Synset</th><th>Definition</th></tr><tr><td>dog.n.01</td><td>a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times; occurs in many breeds</td></tr><tr><td>frump.n.01</td><td>a dull unattractive unpleasant girl or woman</td></tr><tr><td>dog.n.03</td><td>informal term for a man</td></tr><tr><td>cad.n.01</td><td>someone who is morally reprehensible</td></tr><tr><td>frank.n.02</td><td>a smooth-textured sausage of minced beef or pork usually smoked; often served on a bread roll</td></tr><tr><td>pawl.n.01</td><td>a hinged catch that fits into a notch of a ratchet to move a wheel forward or prevent it from moving backward</td></tr><tr><td>andiron.n.01</td><td>metal supports for logs in a fireplace</td></tr><tr><td>chase.v.01</td><td>go after with the intent to catch</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_synsets = wordnet.synsets('dog')\n",
    "print(\"There are {} synsets referring to this word:\".format(len(my_synsets)))\n",
    "\n",
    "data = []\n",
    "for synset in my_synsets:\n",
    "    data.append([synset.name(), synset.definition()])\n",
    "\n",
    "display_table(data, [\"Synset\", \"Definition\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos quedarnos con uno de ellos y explorar la cantidad de información que ofrece WordNet una vez que hemos encontrado el *synset* que nos interesa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synset.name: dog.n.01\n",
      "synset.definition: a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times; occurs in many breeds\n",
      "synset.examples:\n",
      "\t + the dog barked all night\n",
      "synset.lemmas:\n",
      "\t + dog\n",
      "\t + domestic_dog\n",
      "\t + Canis_familiaris\n"
     ]
    }
   ],
   "source": [
    "my_synset = my_synsets[0]  # TODO: Prueba con otros: my_synsets[1], my_synsets[2],...\n",
    "print(\"synset.name: {}\".format(my_synset.name()))\n",
    "print(\"synset.definition: {}\".format(my_synset.definition()))\n",
    "\n",
    "print(\"synset.examples:\")\n",
    "for example in my_synset.examples():\n",
    "    print(\"\\t + {}\".format(example))\n",
    "\n",
    "print(\"synset.lemmas:\")\n",
    "for lemma in my_synset.lemmas():\n",
    "    print(\"\\t + {}\".format(lemma.name()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y también podemos buscar los lemmas correspondientes a un *synset* en otros idiomas. Vamos a mostrar aquí sólo un ejemplo porque trataremos este tema más adelante. Véamos cuáles son los relacionados con el *synset* que hemos guardado en la variable `my_synset` de la celda anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the languages available: als, arb, bul, cat, cmn, dan, ell, eng, eus, fas, fin, fra, glg, heb, hrv, ind, ita, jpn, nno, nob, pol, por, qcn, slv, spa, swe, tha, zsm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table align=\"left\"><tr><th>lang</th><th>lemmas</th></tr><tr><td>eng</td><td>dog</br>domestic_dog</br>Canis_familiaris</td></tr><tr><td>spa</td><td>can</br>perro</td></tr><tr><td>fra</td><td>canis_familiaris</br>chien</td></tr><tr><td>eus</td><td>or</br>txakur</br>zakur</td></tr><tr><td>jpn</td><td>イヌ</br>ドッグ</br>洋犬</br>犬</br>飼犬</br>飼い犬</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "languages = sorted(wordnet.langs())\n",
    "print(\"These are the languages available: {}\".format(', '.join(languages)))\n",
    "\n",
    "selected_languages = ['eng', 'spa', 'fra', 'eus', 'jpn',] # TODO: Prueba con otros idiomas (de la lista)\n",
    "\n",
    "data = []\n",
    "for lang in selected_languages:\n",
    "    data.append([lang, '</br>'.join(my_synset.lemma_names(lang))])\n",
    "\n",
    "display_table(data, headers=[\"lang\", \"lemmas\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categoría gramatical de un synset\n",
    "\n",
    "En el apartado anterior hemos recuperado todos los *synsets* a partir de una palabra y nos han aparecido significados correspondientes a sustantivos, verbos, adjetivos,... pero se puede afinar un poco más la búsqueda utilizando el *part of speech (pos)*:\n",
    "\n",
    " * `wordnet.VERB`\n",
    " * `wordnet.NOUN`\n",
    " * `wordnet.ADJ`\n",
    " * `wordnet.ADV`\n",
    " \n",
    "¡Vamos a verlo en acción!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synsets_as_noun: [Synset('commodity.n.01'), Synset('good.n.03'), Synset('sake.n.01'), Synset('good.n.01'), Synset('personal_property.n.01')]\n"
     ]
    }
   ],
   "source": [
    "word = \"bien\"  # TODO: seguro que se te ocurren palabras que puedan aparecer en varias categorías gramaticales\n",
    "lang = \"spa\"  # TODO: estamos buscando en español, pero...\n",
    "\n",
    "synsets_as_noun = wordnet.synsets(word, lang=lang, pos=wordnet.NOUN)\n",
    "synsets_as_verb = wordnet.synsets(word, lang=lang, pos=wordnet.VERB)\n",
    "synsets_as_adj = wordnet.synsets(word, lang=lang, pos=wordnet.ADJ)\n",
    "synsets_as_adv = wordnet.synsets(word, lang=lang, pos=wordnet.ADV)\n",
    "\n",
    "# Vamos a imprimir los resultados\n",
    "print(\"synsets_as_noun: {}\".format(synsets_as_noun))\n",
    "\n",
    "# TODO: ¿Te atreves a mostrar más información sobre ellos con una tabla?:\n",
    "# def synset_table(synsets, title):\n",
    "#    data = []\n",
    "#    for synset in synsets:\n",
    "#        data.append([synset.name(), synset.lemma_names(), synset.definition()])\n",
    "#        \n",
    "#    display_table(data, [\"Synset\", \"Lemmas\", \"Definition\"], caption=title)\n",
    "#\n",
    "#synset_table(synsets_as_noun, title=\"Resultados con: wordnet.NOUN\")\n",
    "#synset_table(synsets_as_verb, title=\"Resultados con: wordnet.VERB\")\n",
    "#synset_table(synsets_as_adj,  title=\"Resultados con: wordnet.ADJ\")\n",
    "#synset_table(synsets_as_adv, title=\"Resultados con: wordnet.ADV\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lo que nos gusta de los *synsets*\n",
    "\n",
    "Lo que nos gusta de los *synsets* es que permiten referirse a un significado sin ambigüedades. A los ordenadores se les da muy mal resolver ambigüedades, generalmente se les da muy mal todo lo que humanos hacemos con relativa facilidad (entender un mensaje, reconocer imágenes,...), pero realizan muy eficazmente tareas que a nosotros nos cuestan mucho tiempo (búsquedas, ordenación,...).\n",
    "\n",
    "Los ordenadores querrían ver los textos de esta forma, **sin ambigüedades**:\n",
    "\n",
    "```\n",
    "El perro ladra ---> El dog.n.01 bark.v.04\n",
    "```\n",
    "así podrían entenderlo y podríamos hacer inferencias sin equivocarnos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemma\n",
    "\n",
    "No debe confundirse un **synset** con un **lemma**, tal y como los identifica WordNet. Recordemos que:\n",
    " \n",
    " * un **synset** está asociado a un significado, que puede representarse en lenguaje natural mediante palabras (lemmas) muy diferentes: perro, dog, can,...\n",
    " * un **lemma** es una palabra de lenguaje natural y, por lo tanto, puede tener varios significados (synsets).\n",
    " \n",
    "Esta diferencia es importantísima tenerla presente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('dog.n.01') -> Lemma('dog.n.01.dog')\n",
      "Synset('dog.n.01') -> Lemma('dog.n.01.domestic_dog')\n",
      "Synset('dog.n.01') -> Lemma('dog.n.01.Canis_familiaris')\n"
     ]
    }
   ],
   "source": [
    "ex_synset = wordnet.synset('dog.n.01')\n",
    "for lemma in ex_synset.lemmas():\n",
    "    print(\"{} -> {}\".format(ex_synset, lemma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos, a traves de un *synset* llegamos a lemmas diferentes, pero todos ellos con el mismo significado. De hecho, el identificador del sysnset `dog.n.01` se mantiene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog -> Lemma('dog.n.01.dog') -> Synset('dog.n.01')\n",
      "dog -> Lemma('frump.n.01.dog') -> Synset('frump.n.01')\n",
      "dog -> Lemma('dog.n.03.dog') -> Synset('dog.n.03')\n",
      "dog -> Lemma('cad.n.01.dog') -> Synset('cad.n.01')\n",
      "dog -> Lemma('frank.n.02.dog') -> Synset('frank.n.02')\n",
      "dog -> Lemma('pawl.n.01.dog') -> Synset('pawl.n.01')\n",
      "dog -> Lemma('andiron.n.01.dog') -> Synset('andiron.n.01')\n",
      "dog -> Lemma('chase.v.01.dog') -> Synset('chase.v.01')\n"
     ]
    }
   ],
   "source": [
    "ex_lemmas = wordnet.lemmas(\"dog\")\n",
    "for lemma in ex_lemmas:\n",
    "    print(\"{} -> {} -> {}\".format(lemma.name(), lemma, lemma.synset()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En cambio, cuando buscamos una palabra obtenemos varios lemmas, cada uno de ellos asociado a un synset diferente. Se puede observar cómo los identificadores de los synsets son diferentes: `dog.n.01`, `frump.n.01`,..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Qué tal vamos hasta aquí?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-de6a18cefacb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# TODO: Selecciona la imagen que corresponda (sustituye la variable 'img' por una de las de arriba)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHTML\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"<img src='{}' />\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'img' is not defined"
     ]
    }
   ],
   "source": [
    "bien = \"https://media.giphy.com/media/tqxGgrCnQGsHm/giphy.gif\"\n",
    "mal = \"https://media.giphy.com/media/rn0rRhia7343u/giphy.gif\"\n",
    "\n",
    "# TODO: Selecciona la imagen que corresponda (sustituye la variable 'img' por una de las de arriba)\n",
    "display(HTML(\"<img src='{}' />\".format(img)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relaciones\n",
    "\n",
    "Como decíamos al principio, WordNet es más que un diccionario o un traductor, se trata de una **red de conceptos** que nos permite buscar relaciones entre significados de una forma extremadamente fácil e interesante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synset\n",
    "\n",
    "Los elementos de tipo *synset* definen algunas relaciones que puedes explorar. A continuación te indicamos cuáles creemos que son las más interesantes (puedes consultar la lista completa [aquí](http://www.nltk.org/api/nltk.corpus.reader.html#nltk.corpus.reader.wordnet.Synset)):\n",
    "\n",
    " * hiperónimos\n",
    " * hipónimos\n",
    " * holónimos\n",
    " * merónimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_synset = wordnet.synset(\"hand.n.01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hiperónimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table align=\"left\"><caption>Hypernyms for Synset('hand.n.01')</caption><tr><th>hyp-synset</th><th>lemmas</th><th>examples</th></tr><tr><td>Synset('extremity.n.05')</td><td>extremity</td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = []\n",
    "for hypernym in my_synset.hypernyms():\n",
    "    lemmas = [lemma.name() for lemma in hypernym.lemmas()]\n",
    "    data.append([hypernym, ', '.join(lemmas), '</br>'.join(hypernym.examples())])\n",
    "display_table(data, [\"hyp-synset\", \"lemmas\", \"examples\"], caption=\"Hypernyms for {}\".format(my_synset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hipónimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table align=\"left\"><caption>Hyponyms for Synset('hand.n.01')</caption><tr><th>hyponym-synset</th><th>lemmas</th><th>examples</th></tr><tr><td>Synset('fist.n.01')</td><td>fist, clenched_fist</td><td></td></tr><tr><td>Synset('hooks.n.01')</td><td>hooks, meat_hooks, maulers</td><td>wait till I get my hooks on him</td></tr><tr><td>Synset('left.n.03')</td><td>left, left_hand</td><td>jab with your left</td></tr><tr><td>Synset('right.n.05')</td><td>right, right_hand</td><td>he writes with his right hand but pitches with his left</br>hit him with quick rights to the body</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = []\n",
    "for hyponym in my_synset.hyponyms():\n",
    "    lemmas = [lemma.name() for lemma in hyponym.lemmas()]\n",
    "    data.append([hyponym, ', '.join(lemmas), '</br>'.join(hyponym.examples())])\n",
    "display_table(data, [\"hyponym-synset\", \"lemmas\", \"examples\"], caption=\"Hyponyms for {}\".format(my_synset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Holónimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table align=\"left\"><caption>Holonyms for Synset('hand.n.01')</caption><tr><th>holonym-synset</th><th>lemmas</th><th>examples</th></tr><tr><td>Synset('arm.n.01')</td><td>arm</td><td></td></tr><tr><td>Synset('homo.n.02')</td><td>homo, man, human_being, human</td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# member_holonyms, substance_holonyms, part_holonyms\n",
    "data = []\n",
    "for holonym in my_synset.part_holonyms():\n",
    "    lemmas = [lemma.name() for lemma in holonym.lemmas()]\n",
    "    data.append([holonym, ', '.join(lemmas), '</br>'.join(holonym.examples())])\n",
    "display_table(data, [\"holonym-synset\", \"lemmas\", \"examples\"], caption=\"Holonyms for {}\".format(my_synset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merónimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table align=\"left\"><caption>Meronyms for Synset('hand.n.01')</caption><tr><th>meronym-synset</th><th>lemmas</th><th>examples</th></tr><tr><td>Synset('ball.n.10')</td><td>ball</td><td>the ball at the base of the thumb</br>he stood on the balls of his feet</td></tr><tr><td>Synset('digital_arteries.n.01')</td><td>digital_arteries, arteria_digitalis</td><td></td></tr><tr><td>Synset('finger.n.01')</td><td>finger</td><td>her fingers were long and thin</td></tr><tr><td>Synset('intercapitular_vein.n.01')</td><td>intercapitular_vein, vena_intercapitalis</td><td></td></tr><tr><td>Synset('metacarpal_artery.n.01')</td><td>metacarpal_artery, arteria_metacarpea</td><td></td></tr><tr><td>Synset('metacarpal_vein.n.01')</td><td>metacarpal_vein, vena_metacarpus</td><td></td></tr><tr><td>Synset('metacarpus.n.01')</td><td>metacarpus</td><td></td></tr><tr><td>Synset('palm.n.01')</td><td>palm, thenar</td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# member_meronyms, substance_meronyms, part_meronyms\n",
    "data = []\n",
    "for meronym in my_synset.part_meronyms():\n",
    "    lemmas = [lemma.name() for lemma in meronym.lemmas()]\n",
    "    data.append([meronym, ', '.join(lemmas), '</br>'.join(meronym.examples())])\n",
    "display_table(data, [\"meronym-synset\", \"lemmas\", \"examples\"], caption=\"Meronyms for {}\".format(my_synset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemma\n",
    "\n",
    "Los lemas, por su parte, también definen unas cuantas relaciones interesantes (lista completa [aquí](http://www.nltk.org/api/nltk.corpus.reader.html#nltk.corpus.reader.wordnet.Lemma)), si bien, las dos que nos parecen más interesantes son:\n",
    "\n",
    " * antonyms\n",
    " * derivationally_related_forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_lemma = wordnet.lemma(\"fast.a.01.fast\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formas derivadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table align=\"left\"><caption>Derivates for Lemma('fast.a.01.fast')</caption><tr><th>derivationally-related-forms</th><th>lemmas</th><th>examples</th></tr><tr><td>Lemma('speed.n.02.fastness')</td><td>rapidez</br>velocidad</td><td>the project advanced with gratifying speed</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lang='spa'  # TODO: Change the language\n",
    "data = []\n",
    "for item in my_lemma.derivationally_related_forms():\n",
    "    lemmas = item.synset().lemma_names(lang=lang)\n",
    "    data.append([item, '</br>'.join(lemmas), '</br>'.join(item.synset().examples())])\n",
    "display_table(data, [\"derivationally-related-forms\", \"lemmas\", \"examples\"], caption=\"Derivates for {}\".format(my_lemma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Antónimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table align=\"left\"><caption>Antonym for Lemma('fast.a.01.fast')</caption><tr><th>antonym-lemma</th><th>lemmas</th><th>examples</th></tr><tr><td>Lemma('slow.a.01.slow')</td><td>slow</td><td>a slow walker</br>the slow lane of traffic</br>her steps were slow</br>he was slow in reacting to the news</br>slow but steady growth</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lang='eng'  # TODO: Change the language\n",
    "data = []\n",
    "for item in my_lemma.antonyms():\n",
    "    lemmas = item.synset().lemma_names(lang=lang)\n",
    "    data.append([item, '</br>'.join(lemmas), '</br>'.join(item.synset().examples())])\n",
    "display_table(data, [\"antonym-lemma\", \"lemmas\", \"examples\"], caption=\"Antonym for {}\".format(my_lemma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las relaciones entre un elemento y sus vecinos permiten explorar la red de conceptos buscando términos relacionados con una palabra (lema) dada o bien con un concepto (synset) determinado. Sin embargo, esta estructura de relaciones nos permite también abordar problemas mucho más ambiciosos. Algunos de ellos los vemos a continuación:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Expansión de búsquedas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una de las primeras aplicaciones que se nos pueden ocurrir y quizá de las más utilizadas es la expansión de búsquedas. Para ello podemos utilizar estas redes de conceptos para ampliar la búsqueda utilizando otras palabras relacionadas. De este modo lo que se persigue es encontrar documentos que, aunque no contengan exactamente la misma palabra que se ha introducido, sí sean relevantes por contener otras relacionadas.\n",
    "\n",
    "Por ejemplo, si el usuario ha introducido `dalmatian` como término de búsqueda, podemos hacer lo siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original query: dalmatian\n",
      "Expanded to synsets: Dalmatian, carriage_dog, dalmatian, coach_dog\n",
      "Expanded with hyperonyms: Canis_familiaris, domestic_dog, coach_dog, dalmatian, dog, carriage_dog, Dalmatian, European\n"
     ]
    }
   ],
   "source": [
    "q = \"dalmatian\"\n",
    "print(\"Original query: {}\".format(q))\n",
    "\n",
    "# Look synsets related to the keyword\n",
    "synsets = wordnet.synsets(q)\n",
    "\n",
    "# Expand the query to all related synsets\n",
    "def gather_lemmas(synset_list):\n",
    "    lemmas = []\n",
    "    for synset in synset_list:\n",
    "        lemmas += synset.lemma_names()\n",
    "    return lemmas\n",
    "    \n",
    "expanded_query = [q] + gather_lemmas(synsets)\n",
    "print(\"Expanded to synsets: {}\".format(', '.join(set(expanded_query))))\n",
    "\n",
    "# Expand the query to all hyperonyms:\n",
    "for synset in synsets:\n",
    "    expanded_query += gather_lemmas(synset.hypernyms())\n",
    "\n",
    "print(\"Expanded with hyperonyms: {}\".format(', '.join(set(expanded_query))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al tener muchos más términos de búsqueda podremos recuperar muchos más documentos de nuestro corpus en caso de que la búsqueda original ofreciera un numero insuficiente de resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distancia semántica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra aplicación muy habitual cuando se dispone de una red de conceptos es medir la distancia semántica entre significados. Algunas situaciones en las que puede plantearse esta necesidad son la evaluación de traductores (cuál se ha separado menos del significado original) o la desambiguación (ante un mismo lema con varios significados podemos asignarle una probabilidad a cada uno de ellos según la distancia a la temática del documento).\n",
    "\n",
    "Esta aplicación es tan demandada que NLTK implementa los principales algoritmos para calcular esta medida. Por ejemplo, dados tres significados `dog.n.01`, `cat.n.01` y `tiger.n.01`, veamos cuál es la distancia entre ellos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog = wordnet.synset(\"dog.n.01\")\n",
    "cat = wordnet.synset(\"cat.n.01\")\n",
    "tiger = wordnet.synset(\"tiger.n.01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table align=\"left\"><tr><th>Method</th><th>dog.n.01 > dog.n.01</th><th>dog.n.01 > cat.n.01</th><th>dog.n.01 > tiger.n.01</th></tr><tr><td>lch_similarity</td><td>3.6375861597263857</td><td>2.0281482472922856</td><td>1.845826690498331</td></tr><tr><td>wup_similarity</td><td>0.9285714285714286</td><td>0.8571428571428571</td><td>0.7058823529411765</td></tr><tr><td>path_similarity</td><td>1.0</td><td>0.2</td><td>0.16666666666666666</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "items = [dog, cat, tiger]\n",
    "methods = {'path_similarity': wordnet.path_similarity,\n",
    "          'lch_similarity': wordnet.lch_similarity,\n",
    "          'wup_similarity': wordnet.wup_similarity,\n",
    "          #'res_similarity': wordnet.res_similarity,\n",
    "          #'jcn_similarity': wordnet.jcn_similarity,\n",
    "          #'lin_similarity': wordnet.lin_similarity\n",
    "          }\n",
    "\n",
    "data = []\n",
    "for key,method in methods.items():\n",
    "    row = []\n",
    "    it1 = items[0]\n",
    "    for it2 in items:\n",
    "        row.append(method(it1, it2))\n",
    "    data.append([key] + row)\n",
    "\n",
    "display_table(data, [\"Method\", *[\"{} > {}\".format(items[0].name(), it.name()) for it in items]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Especificidad y concreción\n",
    "\n",
    "¡Toma epígrage! Hay un método que te devuelve la profundidad en la jerarquía de conceptos de una palabra, ¿se podría evaluar en base a esto cómo de riguroso es un autor?\n",
    "\n",
    "En primer lugar, ten en cuenta que WordNet no es una estructura en forma de árbol, sino que es un grafo, es decir, ¡puede haber varios caminos para llegar a un mismo nodo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Path:\n",
      "entity.n.01 >> physical_entity.n.01 >> object.n.01 >> whole.n.02 >> living_thing.n.01 >> organism.n.01 >> animal.n.01 >> chordate.n.01 >> vertebrate.n.01 >> mammal.n.01 >> placental.n.01 >> carnivore.n.01 >> canine.n.02 >> dog.n.01\n",
      "== Path:\n",
      "entity.n.01 >> physical_entity.n.01 >> object.n.01 >> whole.n.02 >> living_thing.n.01 >> organism.n.01 >> animal.n.01 >> domestic_animal.n.01 >> dog.n.01\n"
     ]
    }
   ],
   "source": [
    "dog = wordnet.synset('dog.n.01')\n",
    "\n",
    "for path in dog.hypernym_paths():\n",
    "    print(\"== Path:\")\n",
    "    print(' >> '.join([item.name() for item in path]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto es importante porque al calcular la profundidad de un nodo en la jerarquía de conceptos obtendremos varios valores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table align=\"left\"><tr><th>synset</th><th>min_depth</th><th>max_depth</th></tr><tr><td>dalmatian</td><td>6</td><td>9</td></tr><tr><td>dog</td><td>8</td><td>13</td></tr><tr><td>animal</td><td>6</td><td>6</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = {'dog': 'dog.n.01',\n",
    "          'dalmatian': 'dalmatian.n.01',\n",
    "          'animal': 'animal.n.01'}\n",
    "\n",
    "data = []\n",
    "for w,s in words.items():\n",
    "    min_depth = wordnet.synset(s).min_depth()\n",
    "    max_depth = wordnet.synset(s).max_depth()\n",
    "    data.append([w, min_depth, max_depth])\n",
    "    \n",
    "display_table(data, [\"synset\", \"min_depth\", \"max_depth\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "es decir que si queremos comparar la profundidad relativa entre dos conceptos tenemos que procurar evaluar ambos **utilizando el mismo camino** para no obtener resultados indeseados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
