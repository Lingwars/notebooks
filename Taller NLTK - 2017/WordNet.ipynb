{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordNet\n",
    "\n",
    " * [Synsets](#Synsets)\n",
    "    * [Lemma](#Lemma)\n",
    " * [Relaciones](#Relaciones)\n",
    " * [Aplicaciones](#Aplicaciones)\n",
    "    * [Expansión de búsquedas](#Expansión-de-búsquedas)\n",
    "    * [Distancia semántica](#Distancia-semántica)\n",
    "    * [Especificidad y concreción](#Especificidad-y-concreción)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# Import some helpful classes and functions\n",
    "from IPython.display import HTML, display, Image\n",
    "\n",
    "def display_table(data, headers=None, caption=None):\n",
    "    html = [\"<table align=\\\"left\\\">\"]\n",
    "    \n",
    "    if caption:\n",
    "        html += [\"<caption>{}</caption>\".format(caption)]\n",
    "        \n",
    "    if headers:\n",
    "        html += [\"<tr>\"] + [\"<th>{}</th>\".format(h) for h in headers] + [\"</tr>\"]\n",
    "    \n",
    "    for row in data:\n",
    "        html += [\"<tr>\"]\n",
    "        html += [\"<td>{}</td>\".format(it) for it in row]\n",
    "        html += [\"</tr>\"]\n",
    "\n",
    "    html.append(\"</table>\")\n",
    "    display(HTML(''.join(html)))    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qué es WordNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[WordNet](https://wordnet.princeton.edu/) es una red de conceptos que contiene información codificada manualmente sobre sustantivos, verbos, adjetivos y adverbios en inglés; los términos que representan un mismo concepto están agrupados en *synsets* y son estos elementos los que constituyen los nodos de la red.\n",
    "\n",
    "WordNet se creó en el Laboratorio de Ciencia Cognitiva de la Universidad de Princeton en 1985 bajo la dirección del profesor de psicología George Armitage Miller (1920-2012)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synsets\n",
    "\n",
    "Un synset es un conjunto de palabras de la misma categoría gramatical que hacen referencia a la misma realidad extralingüística y por lo tanto pueden ser intercambiadas en un texto sin afectar al significado. Son elementos semánticamente equivalentes. Así, ocurrirá que las palabras polisémicas aparecerán múltiples veces en *synsets* diferentes.\n",
    "\n",
    "Podemos hacer una búsqueda de uno de estos *synsets* utilizando la función `synsets`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8 synsets referring to this word:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table align=\"left\"><tr><th>Synset</th><th>Definition</th></tr><tr><td>dog.n.01</td><td>a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times; occurs in many breeds</td></tr><tr><td>frump.n.01</td><td>a dull unattractive unpleasant girl or woman</td></tr><tr><td>dog.n.03</td><td>informal term for a man</td></tr><tr><td>cad.n.01</td><td>someone who is morally reprehensible</td></tr><tr><td>frank.n.02</td><td>a smooth-textured sausage of minced beef or pork usually smoked; often served on a bread roll</td></tr><tr><td>pawl.n.01</td><td>a hinged catch that fits into a notch of a ratchet to move a wheel forward or prevent it from moving backward</td></tr><tr><td>andiron.n.01</td><td>metal supports for logs in a fireplace</td></tr><tr><td>chase.v.01</td><td>go after with the intent to catch</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_synsets = wordnet.synsets('dog')\n",
    "print(\"There are {} synsets referring to this word:\".format(len(my_synsets)))\n",
    "\n",
    "data = []\n",
    "for synset in my_synsets:\n",
    "    data.append([synset.name(), synset.definition()])\n",
    "\n",
    "display_table(data, [\"Synset\", \"Definition\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos quedarnos con uno de ellos y explorar la cantidad de información que ofrece WordNet una vez que hemos encontrado el *synset* que nos interesa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synset.name: dog.n.01\n",
      "synset.definition: a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times; occurs in many breeds\n",
      "synset.examples:\n",
      "\t + the dog barked all night\n",
      "synset.lemmas:\n",
      "\t + dog\n",
      "\t + domestic_dog\n",
      "\t + Canis_familiaris\n"
     ]
    }
   ],
   "source": [
    "my_synset = my_synsets[0]  # TODO: Prueba con otros: my_synsets[1], my_synsets[2],...\n",
    "print(\"synset.name: {}\".format(my_synset.name()))\n",
    "print(\"synset.definition: {}\".format(my_synset.definition()))\n",
    "\n",
    "print(\"synset.examples:\")\n",
    "for example in my_synset.examples():\n",
    "    print(\"\\t + {}\".format(example))\n",
    "\n",
    "print(\"synset.lemmas:\")\n",
    "for lemma in my_synset.lemmas():\n",
    "    print(\"\\t + {}\".format(lemma.name()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y también podemos buscar los lemmas correspondientes a un *synset* en otros idiomas. Vamos a mostrar aquí sólo un ejemplo porque trataremos este tema más adelante. Véamos cuáles son los relacionados con el *synset* que hemos guardado en la variable `my_synset` de la celda anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the languages available: als, arb, bul, cat, cmn, dan, ell, eng, eus, fas, fin, fra, glg, heb, hrv, ind, ita, jpn, nno, nob, pol, por, qcn, slv, spa, swe, tha, zsm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table align=\"left\"><tr><th>lang</th><th>lemmas</th></tr><tr><td>eng</td><td>dog</br>domestic_dog</br>Canis_familiaris</td></tr><tr><td>spa</td><td>can</br>perro</td></tr><tr><td>fra</td><td>canis_familiaris</br>chien</td></tr><tr><td>eus</td><td>or</br>txakur</br>zakur</td></tr><tr><td>jpn</td><td>イヌ</br>ドッグ</br>洋犬</br>犬</br>飼犬</br>飼い犬</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "languages = sorted(wordnet.langs())\n",
    "print(\"These are the languages available: {}\".format(', '.join(languages)))\n",
    "\n",
    "selected_languages = ['eng', 'spa', 'fra', 'eus', 'jpn',] # TODO: Prueba con otros idiomas (de la lista)\n",
    "\n",
    "data = []\n",
    "for lang in selected_languages:\n",
    "    data.append([lang, '</br>'.join(my_synset.lemma_names(lang))])\n",
    "\n",
    "display_table(data, headers=[\"lang\", \"lemmas\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categoría gramatical de un synset\n",
    "\n",
    "En el apartado anterior hemos recuperado todos los *synsets* a partir de una palabra y nos han aparecido significados correspondientes a sustantivos, verbos, adjetivos,... pero se puede afinar un poco más la búsqueda utilizando el *part of speech (pos)*:\n",
    "\n",
    " * `wordnet.VERB`\n",
    " * `wordnet.NOUN`\n",
    " * `wordnet.ADJ`\n",
    " * `wordnet.ADV`\n",
    " \n",
    "¡Vamos a verlo en acción!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synsets_as_noun: [Synset('commodity.n.01'), Synset('good.n.03'), Synset('sake.n.01'), Synset('good.n.01'), Synset('personal_property.n.01')]\n"
     ]
    }
   ],
   "source": [
    "word = \"bien\"  # TODO: seguro que se te ocurren palabras que puedan aparecer en varias categorías gramaticales\n",
    "lang = \"spa\"  # TODO: estamos buscando en español, pero...\n",
    "\n",
    "synsets_as_noun = wordnet.synsets(word, lang=lang, pos=wordnet.NOUN)\n",
    "synsets_as_verb = wordnet.synsets(word, lang=lang, pos=wordnet.VERB)\n",
    "synsets_as_adj = wordnet.synsets(word, lang=lang, pos=wordnet.ADJ)\n",
    "synsets_as_adv = wordnet.synsets(word, lang=lang, pos=wordnet.ADV)\n",
    "\n",
    "# Vamos a imprimir los resultados\n",
    "print(\"synsets_as_noun: {}\".format(synsets_as_noun))\n",
    "\n",
    "# TODO: ¿Te atreves a mostrar más información sobre ellos con una tabla?:\n",
    "# def synset_table(synsets, title):\n",
    "#    data = []\n",
    "#    for synset in synsets:\n",
    "#        data.append([synset.name(), synset.lemma_names(), synset.definition()])\n",
    "#        \n",
    "#    display_table(data, [\"Synset\", \"Lemmas\", \"Definition\"], caption=title)\n",
    "#\n",
    "#synset_table(synsets_as_noun, title=\"Resultados con: wordnet.NOUN\")\n",
    "#synset_table(synsets_as_verb, title=\"Resultados con: wordnet.VERB\")\n",
    "#synset_table(synsets_as_adj,  title=\"Resultados con: wordnet.ADJ\")\n",
    "#synset_table(synsets_as_adv, title=\"Resultados con: wordnet.ADV\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lo que nos gusta de los *synsets*\n",
    "\n",
    "Lo que nos gusta de los *synsets* es que permiten referirse a un significado sin ambigüedades. A los ordenadores se les da muy mal resolver ambigüedades, generalmente se les da muy mal todo lo que humanos hacemos con relativa facilidad (entender un mensaje, reconocer imágenes,...), pero realizan muy eficazmente tareas que a nosotros nos cuestan mucho tiempo (búsquedas, ordenación,...).\n",
    "\n",
    "Los ordenadores querrían ver los textos de esta forma, **sin ambigüedades**:\n",
    "\n",
    "```\n",
    "El perro ladra ---> El dog.n.01 bark.v.04\n",
    "```\n",
    "así podrían entenderlo y podríamos hacer inferencias sin equivocarnos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemma\n",
    "\n",
    "No debe confundirse un **synset** con un **lemma**, tal y como los identifica WordNet. Recordemos que:\n",
    " \n",
    " * un **synset** está asociado a un significado, que puede representarse en lenguaje natural mediante palabras (lemmas) muy diferentes: perro, dog, can,...\n",
    " * un **lemma** es una palabra de lenguaje natural y, por lo tanto, puede tener varios significados (synsets).\n",
    " \n",
    "Esta diferencia es importantísima tenerla presente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('dog.n.01') -> Lemma('dog.n.01.dog')\n",
      "Synset('dog.n.01') -> Lemma('dog.n.01.domestic_dog')\n",
      "Synset('dog.n.01') -> Lemma('dog.n.01.Canis_familiaris')\n"
     ]
    }
   ],
   "source": [
    "ex_synset = wordnet.synset('dog.n.01')\n",
    "for lemma in ex_synset.lemmas():\n",
    "    print(\"{} -> {}\".format(ex_synset, lemma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos, a traves de un *synset* llegamos a lemmas diferentes, pero todos ellos con el mismo significado. De hecho, el identificador del sysnset `dog.n.01` se mantiene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog -> Lemma('dog.n.01.dog') -> Synset('dog.n.01')\n",
      "dog -> Lemma('frump.n.01.dog') -> Synset('frump.n.01')\n",
      "dog -> Lemma('dog.n.03.dog') -> Synset('dog.n.03')\n",
      "dog -> Lemma('cad.n.01.dog') -> Synset('cad.n.01')\n",
      "dog -> Lemma('frank.n.02.dog') -> Synset('frank.n.02')\n",
      "dog -> Lemma('pawl.n.01.dog') -> Synset('pawl.n.01')\n",
      "dog -> Lemma('andiron.n.01.dog') -> Synset('andiron.n.01')\n",
      "dog -> Lemma('chase.v.01.dog') -> Synset('chase.v.01')\n"
     ]
    }
   ],
   "source": [
    "ex_lemmas = wordnet.lemmas(\"dog\")\n",
    "for lemma in ex_lemmas:\n",
    "    print(\"{} -> {} -> {}\".format(lemma.name(), lemma, lemma.synset()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En cambio, cuando buscamos una palabra obtenemos varios lemmas, cada uno de ellos asociado a un synset diferente. Se puede observar cómo los identificadores de los synsets son diferentes: `dog.n.01`, `frump.n.01`,..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Qué tal vamos hasta aquí?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bien = \"https://media.giphy.com/media/tqxGgrCnQGsHm/giphy.gif\"\n",
    "mal = \"https://media.giphy.com/media/rn0rRhia7343u/giphy.gif\"\n",
    "\n",
    "# TODO: Selecciona la imagen que corresponda (sustituye la variable 'img' por una de las de arriba)\n",
    "# display(HTML(\"<img src='{}' />\".format(img)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relaciones\n",
    "\n",
    "Como decíamos al principio, WordNet es más que un diccionario o un traductor, se trata de una **red de conceptos** que nos permite buscar relaciones entre significados de una forma extremadamente fácil e interesante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synset\n",
    "\n",
    "Los elementos de tipo *synset* definen algunas relaciones que puedes explorar. A continuación te indicamos cuáles creemos que son las más interesantes (puedes consultar la lista completa [aquí](http://www.nltk.org/api/nltk.corpus.reader.html#nltk.corpus.reader.wordnet.Synset)):\n",
    "\n",
    " * hiperónimos\n",
    " * hipónimos\n",
    " * holónimos\n",
    " * merónimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_synset = wordnet.synset(\"hand.n.01\")  # TODO: Prueba con otras palabras para ver sus hiperónimos, hipónimos,..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hiperónimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table align=\"left\"><caption>Hypernyms for Synset('hand.n.01')</caption><tr><th>hyp-synset</th><th>lemmas</th><th>examples</th></tr><tr><td>Synset('extremity.n.05')</td><td>extremity</td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = []\n",
    "for hypernym in my_synset.hypernyms():\n",
    "    lemmas = [lemma.name() for lemma in hypernym.lemmas()]\n",
    "    data.append([hypernym, ', '.join(lemmas), '</br>'.join(hypernym.examples())])\n",
    "display_table(data, [\"hyp-synset\", \"lemmas\", \"examples\"], caption=\"Hypernyms for {}\".format(my_synset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además de los hiperónimos a nivel de significado, también existen a nivel de instancia `instance_hypernyms` (igual con los hipónimos). Por ejemplo, si hemos encontrado en un texto la entidad (ver NER) `Vargas Llosa` gracias a WordNet podemos hacer lo siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Había buscado: Zweig\n",
      "zweig.n.01 is a writer.n.01\n",
      "Otras formas de llamarlo son: Zweig, Stefan_Zweig\n",
      "Su 'definición' es: Austrian writer (1881-1942)\n"
     ]
    }
   ],
   "source": [
    "q = \"Zweig\"  # TODO: Prueba otros como p.ej.: Vargas_Llosa, Zweig, Einstein\n",
    "\n",
    "ner = wordnet.synsets(q)[0]  # Recoge el primer resultado\n",
    "hiperonimos = ner.instance_hypernyms()[0]  # Busca sus hiperónimos y quédate con el primero\n",
    "\n",
    "# Qué tengo?\n",
    "print(\"Había buscado: {}\".format(q))\n",
    "print(\"{} is a {}\".format(ner.name(), hiperonimos.name()))  # Su hiperónimo me dice su profesión!!\n",
    "print(\"Otras formas de llamarlo son: {}\".format(', '.join([it.name() for it in ner.lemmas()])))\n",
    "print(\"Su 'definición' es: {}\".format(ner.definition()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hipónimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table align=\"left\"><caption>Hyponyms for Synset('hand.n.01')</caption><tr><th>hyponym-synset</th><th>lemmas</th><th>examples</th></tr><tr><td>Synset('fist.n.01')</td><td>fist, clenched_fist</td><td></td></tr><tr><td>Synset('hooks.n.01')</td><td>hooks, meat_hooks, maulers</td><td>wait till I get my hooks on him</td></tr><tr><td>Synset('left.n.03')</td><td>left, left_hand</td><td>jab with your left</td></tr><tr><td>Synset('right.n.05')</td><td>right, right_hand</td><td>he writes with his right hand but pitches with his left</br>hit him with quick rights to the body</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = []\n",
    "for hyponym in my_synset.hyponyms():\n",
    "    lemmas = [lemma.name() for lemma in hyponym.lemmas()]\n",
    "    data.append([hyponym, ', '.join(lemmas), '</br>'.join(hyponym.examples())])\n",
    "display_table(data, [\"hyponym-synset\", \"lemmas\", \"examples\"], caption=\"Hyponyms for {}\".format(my_synset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Holónimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table align=\"left\"><caption>Holonyms for Synset('hand.n.01')</caption><tr><th>holonym-synset</th><th>lemmas</th><th>examples</th></tr><tr><td>Synset('arm.n.01')</td><td>arm</td><td></td></tr><tr><td>Synset('homo.n.02')</td><td>homo, man, human_being, human</td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# member_holonyms, substance_holonyms, part_holonyms\n",
    "data = []\n",
    "for holonym in my_synset.part_holonyms():\n",
    "    lemmas = [lemma.name() for lemma in holonym.lemmas()]\n",
    "    data.append([holonym, ', '.join(lemmas), '</br>'.join(holonym.examples())])\n",
    "display_table(data, [\"holonym-synset\", \"lemmas\", \"examples\"], caption=\"Holonyms for {}\".format(my_synset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merónimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table align=\"left\"><caption>Meronyms for Synset('hand.n.01')</caption><tr><th>meronym-synset</th><th>lemmas</th><th>examples</th></tr><tr><td>Synset('ball.n.10')</td><td>ball</td><td>the ball at the base of the thumb</br>he stood on the balls of his feet</td></tr><tr><td>Synset('digital_arteries.n.01')</td><td>digital_arteries, arteria_digitalis</td><td></td></tr><tr><td>Synset('finger.n.01')</td><td>finger</td><td>her fingers were long and thin</td></tr><tr><td>Synset('intercapitular_vein.n.01')</td><td>intercapitular_vein, vena_intercapitalis</td><td></td></tr><tr><td>Synset('metacarpal_artery.n.01')</td><td>metacarpal_artery, arteria_metacarpea</td><td></td></tr><tr><td>Synset('metacarpal_vein.n.01')</td><td>metacarpal_vein, vena_metacarpus</td><td></td></tr><tr><td>Synset('metacarpus.n.01')</td><td>metacarpus</td><td></td></tr><tr><td>Synset('palm.n.01')</td><td>palm, thenar</td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# member_meronyms, substance_meronyms, part_meronyms\n",
    "data = []\n",
    "for meronym in my_synset.part_meronyms():\n",
    "    lemmas = [lemma.name() for lemma in meronym.lemmas()]\n",
    "    data.append([meronym, ', '.join(lemmas), '</br>'.join(meronym.examples())])\n",
    "display_table(data, [\"meronym-synset\", \"lemmas\", \"examples\"], caption=\"Meronyms for {}\".format(my_synset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemma\n",
    "\n",
    "Los lemas, por su parte, también definen unas cuantas relaciones interesantes (lista completa [aquí](http://www.nltk.org/api/nltk.corpus.reader.html#nltk.corpus.reader.wordnet.Lemma)), si bien, las dos que nos parecen más interesantes son:\n",
    "\n",
    " * antonyms\n",
    " * derivationally_related_forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_lemma = wordnet.lemma(\"fast.a.01.fast\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formas derivadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table align=\"left\"><caption>Derivates for Lemma('fast.a.01.fast')</caption><tr><th>derivationally-related-forms</th><th>lemmas</th><th>examples</th></tr><tr><td>Lemma('speed.n.02.fastness')</td><td>rapidez</br>velocidad</td><td>the project advanced with gratifying speed</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lang='spa'  # TODO: Change the language\n",
    "data = []\n",
    "for item in my_lemma.derivationally_related_forms():\n",
    "    lemmas = item.synset().lemma_names(lang=lang)\n",
    "    data.append([item, '</br>'.join(lemmas), '</br>'.join(item.synset().examples())])\n",
    "display_table(data, [\"derivationally-related-forms\", \"lemmas\", \"examples\"], caption=\"Derivates for {}\".format(my_lemma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Antónimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table align=\"left\"><caption>Antonym for Lemma('fast.a.01.fast')</caption><tr><th>antonym-lemma</th><th>lemmas</th><th>examples</th></tr><tr><td>Lemma('slow.a.01.slow')</td><td>slow</td><td>a slow walker</br>the slow lane of traffic</br>her steps were slow</br>he was slow in reacting to the news</br>slow but steady growth</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lang='eng'  # TODO: Change the language\n",
    "data = []\n",
    "for item in my_lemma.antonyms():\n",
    "    lemmas = item.synset().lemma_names(lang=lang)\n",
    "    data.append([item, '</br>'.join(lemmas), '</br>'.join(item.synset().examples())])\n",
    "display_table(data, [\"antonym-lemma\", \"lemmas\", \"examples\"], caption=\"Antonym for {}\".format(my_lemma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las relaciones entre un elemento y sus vecinos permiten explorar la red de conceptos buscando términos relacionados con una palabra (lema) dada o bien con un concepto (synset) determinado. Sin embargo, esta estructura de relaciones nos permite también abordar problemas mucho más ambiciosos. Algunos de ellos los vemos a continuación:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Expansión de búsquedas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una de las primeras aplicaciones que se nos pueden ocurrir y quizá de las más utilizadas es la expansión de búsquedas. Para ello podemos utilizar estas redes de conceptos para ampliar la búsqueda utilizando otras palabras relacionadas. De este modo lo que se persigue es encontrar documentos que, aunque no contengan exactamente la misma palabra que se ha introducido, sí sean relevantes por contener otras relacionadas.\n",
    "\n",
    "Por ejemplo, si el usuario ha introducido `dalmatian` como término de búsqueda, podemos hacer lo siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original query: dalmatian\n",
      "Expanded to synsets: carriage_dog, coach_dog, Dalmatian, dalmatian\n",
      "Expanded with hyperonyms: European, coach_dog, Dalmatian, dog, Canis_familiaris, carriage_dog, domestic_dog, dalmatian\n"
     ]
    }
   ],
   "source": [
    "q = \"dalmatian\"\n",
    "print(\"Original query: {}\".format(q))\n",
    "\n",
    "# Look synsets related to the keyword\n",
    "synsets = wordnet.synsets(q)\n",
    "\n",
    "# Expand the query to all related synsets\n",
    "def gather_lemmas(synset_list):\n",
    "    lemmas = []\n",
    "    for synset in synset_list:\n",
    "        lemmas += synset.lemma_names()\n",
    "    return lemmas\n",
    "    \n",
    "expanded_query = [q] + gather_lemmas(synsets)\n",
    "print(\"Expanded to synsets: {}\".format(', '.join(set(expanded_query))))\n",
    "\n",
    "# Expand the query to all hyperonyms:\n",
    "for synset in synsets:\n",
    "    expanded_query += gather_lemmas(synset.hypernyms())\n",
    "\n",
    "print(\"Expanded with hyperonyms: {}\".format(', '.join(set(expanded_query))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al tener muchos más términos de búsqueda podremos recuperar muchos más documentos de nuestro corpus en caso de que la búsqueda original ofreciera un numero insuficiente de resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distancia semántica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra aplicación muy habitual cuando se dispone de una red de conceptos es medir la distancia semántica entre significados. Algunas situaciones en las que puede plantearse esta necesidad son la evaluación de traductores (cuál se ha separado menos del significado original) o la desambiguación (ante un mismo lema con varios significados podemos asignarle una probabilidad a cada uno de ellos según la distancia a la temática del documento).\n",
    "\n",
    "Esta aplicación es tan demandada que NLTK implementa los principales algoritmos para calcular esta medida. Por ejemplo, dados tres significados `dog.n.01`, `cat.n.01` y `tiger.n.01`, veamos cuál es la distancia entre ellos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The similarity between Synset('dog.n.01') and Synset('cat.n.01') using the given algorithm is 0.2000\n"
     ]
    }
   ],
   "source": [
    "synset1 = wordnet.synset(\"dog.n.01\")\n",
    "synset2 = wordnet.synset(\"cat.n.01\")\n",
    "sim = wordnet.path_similarity(synset1, synset2)\n",
    "\n",
    "print(\"The similarity between {} and {} using the given algorithm is {:0.4f}\".format(synset1, synset2, sim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a definir ahora una lista en las que incorporaremos todas las funciones que ofrece WordNet para el cálculo de la similaridad entre dos *synsets*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Métodos básicos para calcular similitud entre dos términos\n",
    "methods = [('path_similarity', wordnet.path_similarity),\n",
    "           ('Leacock-Chodorow', wordnet.lch_similarity),\n",
    "           ('Wu-Palmer', wordnet.wup_similarity),]\n",
    "\n",
    "# Algunos algoritmos necesitan un 'corpus' para utilizarlo como referencia\n",
    "from nltk.corpus import wordnet_ic, genesis\n",
    "brown_ic = wordnet_ic.ic('ic-brown.dat')\n",
    "semcor_ic = wordnet_ic.ic('ic-semcor.dat')\n",
    "genesis_ic = wordnet.ic(genesis, False, 0.0) # Esto puede tardar un poco la primera vez\n",
    "\n",
    "methods_ic = [('Resnik + Brown', lambda u,v: wordnet.res_similarity(u, v, brown_ic)),\n",
    "              ('Resnik + Semcor', lambda u,v: wordnet.res_similarity(u, v, semcor_ic)),\n",
    "              ('Resnik + Genesis', lambda u,v: wordnet.res_similarity(u, v, genesis_ic)),\n",
    "                \n",
    "              ('Jiang-Conrath + Brown', lambda u,v: wordnet.jcn_similarity(u, v, brown_ic)),\n",
    "              ('Jiang-Conrath + Semcor', lambda u,v: wordnet.jcn_similarity(u, v, semcor_ic)),\n",
    "              ('Jiang-Conrath + Genesis', lambda u,v: wordnet.jcn_similarity(u, v, genesis_ic)),\n",
    "           \n",
    "              ('Lin + Brown', lambda u,v: wordnet.lin_similarity(u, v, brown_ic)),\n",
    "              ('Lin + Semcor', lambda u,v: wordnet.lin_similarity(u, v, semcor_ic)),\n",
    "              ('Lin + Genesis', lambda u,v: wordnet.lin_similarity(u, v, genesis_ic)),]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y también una función para mostrar los resultados de nuestros cálculos en una tabla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "float_format = \"{0:.4f}\"\n",
    "\n",
    "def compute_distances(item_list, method_list):\n",
    "    data = []\n",
    "    it1 = item_list[0]\n",
    "    for key,method in method_list:\n",
    "        max_similarity = method(it1, it1)\n",
    "        row = [float_format.format(1.0),]\n",
    "\n",
    "        for it2 in item_list[1:]:\n",
    "            similitud = method(it1, it2)/max_similarity  # Normalized by 'similarity(it1, it1)'\n",
    "            row.append(float_format.format(similitud)) \n",
    "        data.append([key] + row)\n",
    "\n",
    "    columns = [\"{} > {}\".format(item_list[0].name(), it.name()) for it in item_list]\n",
    "    display_table(data, [\"Method\"] + columns, caption=\"Similitud normalizada entre '{}'\".format(it1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con los elementos anteriores, la lista de algoritmos y la función auxiliar, podemos empezar a calcular cosas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table align=\"left\"><caption>Similitud normalizada entre 'Synset('dog.n.01')'</caption><tr><th>Method</th><th>dog.n.01 > dog.n.01</th><th>dog.n.01 > cat.n.01</th><th>dog.n.01 > tiger.n.01</th></tr><tr><td>path_similarity</td><td>1.0000</td><td>0.2000</td><td>0.1667</td></tr><tr><td>Leacock-Chodorow</td><td>1.0000</td><td>0.5576</td><td>0.5074</td></tr><tr><td>Wu-Palmer</td><td>1.0000</td><td>0.9231</td><td>0.7602</td></tr><tr><td>Resnik + Brown</td><td>1.0000</td><td>0.8785</td><td>0.2470</td></tr><tr><td>Resnik + Semcor</td><td>1.0000</td><td>0.9373</td><td>0.2355</td></tr><tr><td>Resnik + Genesis</td><td>1.0000</td><td>0.7236</td><td>0.1445</td></tr><tr><td>Jiang-Conrath + Brown</td><td>1.0000</td><td>0.0000</td><td>0.0000</td></tr><tr><td>Jiang-Conrath + Semcor</td><td>1.0000</td><td>0.0000</td><td>0.0000</td></tr><tr><td>Jiang-Conrath + Genesis</td><td>1.0000</td><td>0.0000</td><td>0.0000</td></tr><tr><td>Lin + Brown</td><td>1.0000</td><td>0.8768</td><td>0.2091</td></tr><tr><td>Lin + Semcor</td><td>1.0000</td><td>0.8863</td><td>0.1869</td></tr><tr><td>Lin + Genesis</td><td>1.0000</td><td>0.8044</td><td>0.0000</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dog = wordnet.synset(\"dog.n.01\")\n",
    "cat = wordnet.synset(\"cat.n.01\")\n",
    "tiger = wordnet.synset(\"tiger.n.01\")\n",
    "animals = [dog, cat, tiger] # TODO: Aquí puedes añadir más synsets\n",
    "\n",
    "compute_distances(animals, methods + methods_ic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Einstein is a physicist\n",
      "Austen is a writer\n",
      "Zweig is a writer\n",
      "Cousteau is a explorer\n",
      "Akhenaton is a king\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table align=\"left\"><caption>Similitud normalizada entre 'Synset('einstein.n.01')'</caption><tr><th>Method</th><th>einstein.n.01 > einstein.n.01</th><th>einstein.n.01 > austen.n.01</th><th>einstein.n.01 > zweig.n.01</th><th>einstein.n.01 > cousteau.n.01</th><th>einstein.n.01 > akhenaton.n.01</th></tr><tr><td>path_similarity</td><td>1.0000</td><td>0.1429</td><td>0.1429</td><td>0.1667</td><td>0.1250</td></tr><tr><td>Leacock-Chodorow</td><td>1.0000</td><td>0.4651</td><td>0.4651</td><td>0.5074</td><td>0.4283</td></tr><tr><td>Wu-Palmer</td><td>1.0000</td><td>0.6000</td><td>0.6000</td><td>0.6316</td><td>0.5714</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table align=\"left\"><caption>Similitud normalizada entre 'Synset('zweig.n.01')'</caption><tr><th>Method</th><th>zweig.n.01 > zweig.n.01</th><th>zweig.n.01 > einstein.n.01</th><th>zweig.n.01 > austen.n.01</th><th>zweig.n.01 > cousteau.n.01</th><th>zweig.n.01 > akhenaton.n.01</th></tr><tr><td>path_similarity</td><td>1.0000</td><td>0.1429</td><td>0.3333</td><td>0.1667</td><td>0.1250</td></tr><tr><td>Leacock-Chodorow</td><td>1.0000</td><td>0.4651</td><td>0.6980</td><td>0.5074</td><td>0.4283</td></tr><tr><td>Wu-Palmer</td><td>1.0000</td><td>0.6000</td><td>0.6000</td><td>0.6316</td><td>0.5714</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p1 = wordnet.synset(\"Einstein.n.01\")\n",
    "p2 = wordnet.synset(\"Austen.n.01\")\n",
    "p3 = wordnet.synset(\"Zweig.n.01\")\n",
    "p4 = wordnet.synset(\"Cousteau.n.01\")\n",
    "p5 = wordnet.synset(\"akhenaton.n.01\")\n",
    "people = [p1, p2, p3, p4, p5] # TODO: Aquí puedes añadir más synsets\n",
    "\n",
    "for it in people:\n",
    "    hyp = it.instance_hypernyms()[0]\n",
    "    print(\"{} is a {}\".format(it.lemmas()[0].name(), hyp.lemmas()[0].name()))\n",
    "\n",
    "compute_distances([p1, p2, p3, p4, p5], methods)\n",
    "compute_distances([p3, p1, p2, p4, p5], methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desambiguación\n",
    "\n",
    "El problema clásico y ¿sin solución definitiva? del Procesamiento de Lenguaje Natural: desambiguar el significado de una palabra. Una forma de abordarlo que se me ocurre con lo que sabemos hasta ahora:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence = \"El banco presta dinero a cambio de un interés\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sabemos tokenizar y realizar el análisis sintáctico de una oración. Con ello obtendremos las palabras individuales y el *part of speech* de cada una de ellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence = [(\"bank\", \"n\"), (\"lend\", \"v\"), (\"money\", \"n\"), (\"interest\", \"n\")]\n",
    "\n",
    "# Remove everything but nouns (WordNet does not retrieve similarity for different part of speech synsets)\n",
    "sentence = [(it, pos) for it, pos in sentence if pos==\"n\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviamente tenemos un problema de desambiguación puesto que cada una de estas palabras puede tener diferentes significados. Vamos a listarlos todos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>Significados de bank:</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table align=\"left\"><tr><td>Synset('bank.n.01')</td><td>bank</td><td>sloping land (especially the slope beside a body of water)</td></tr><tr><td>Synset('depository_financial_institution.n.01')</td><td>depository_financial_institution, bank, banking_concern, banking_company</td><td>a financial institution that accepts deposits and channels the money into lending activities</td></tr><tr><td>Synset('bank.n.03')</td><td>bank</td><td>a long ridge or pile</td></tr><tr><td>Synset('bank.n.04')</td><td>bank</td><td>an arrangement of similar objects in a row or in tiers</td></tr><tr><td>Synset('bank.n.05')</td><td>bank</td><td>a supply or stock held in reserve for future use (especially in emergencies)</td></tr><tr><td>Synset('bank.n.06')</td><td>bank</td><td>the funds held by a gambling house or the dealer in some gambling games</td></tr><tr><td>Synset('bank.n.07')</td><td>bank, cant, camber</td><td>a slope in the turn of a road or track; the outside is higher than the inside in order to reduce the effects of centrifugal force</td></tr><tr><td>Synset('savings_bank.n.02')</td><td>savings_bank, coin_bank, money_box, bank</td><td>a container (usually with a slot in the top) for keeping money at home</td></tr><tr><td>Synset('bank.n.09')</td><td>bank, bank_building</td><td>a building in which the business of banking transacted</td></tr><tr><td>Synset('bank.n.10')</td><td>bank</td><td>a flight maneuver; aircraft tips laterally about its longitudinal axis (especially in turning)</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong>Significados de money:</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table align=\"left\"><tr><td>Synset('money.n.01')</td><td>money</td><td>the most common medium of exchange; functions as legal tender</td></tr><tr><td>Synset('money.n.02')</td><td>money</td><td>wealth reckoned in terms of money</td></tr><tr><td>Synset('money.n.03')</td><td>money</td><td>the official currency issued by a government or national bank</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong>Significados de interest:</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table align=\"left\"><tr><td>Synset('interest.n.01')</td><td>interest, involvement</td><td>a sense of concern with and curiosity about someone or something</td></tr><tr><td>Synset('sake.n.01')</td><td>sake, interest</td><td>a reason for wanting something done</td></tr><tr><td>Synset('interest.n.03')</td><td>interest, interestingness</td><td>the power of attracting or holding one's attention (because it is unusual or exciting etc.)</td></tr><tr><td>Synset('interest.n.04')</td><td>interest</td><td>a fixed charge for borrowing money; usually a percentage of the amount borrowed</td></tr><tr><td>Synset('interest.n.05')</td><td>interest, stake</td><td>(law) a right or legal share of something; a financial involvement with something</td></tr><tr><td>Synset('interest.n.06')</td><td>interest, interest_group</td><td>(usually plural) a social group whose members control some field of activity and who have common aims</td></tr><tr><td>Synset('pastime.n.01')</td><td>pastime, interest, pursuit</td><td>a diversion that occupies one's time and thoughts (usually pleasantly)</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for word, pos in sentence:\n",
    "    display(HTML(\"<strong>Significados de {}:</strong>\".format(word)))\n",
    "\n",
    "    synsets = wordnet.synsets(word, pos=pos)\n",
    "    data = []\n",
    "    for s in synsets:\n",
    "        data.append([s, ', '.join([it.name() for it in s.lemmas()]), s.definition()])\n",
    "        \n",
    "    display_table(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "La estrategia que vamos a seguir es probar todas las combinaciones posibles y quedarnos con aquélla que ofrezca la mayor similitud entre sus componentes. ¿Aproximación válida? ¿Inválida? ¿Muy costosa computacionalmente?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "There are 210 possible combinations!!"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Top 10 are:"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table align=\"left\"><tr><th>score</th><th>bank</th><th>money</th><th>interest</th></tr><tr><td>0.4857</td><td>bank.n.06: bank</td><td>money.n.02: money</td><td>interest.n.05: interest, stake</td></tr><tr><td>0.3818</td><td>bank.n.06: bank</td><td>money.n.01: money</td><td>interest.n.05: interest, stake</td></tr><tr><td>0.3778</td><td>bank.n.04: bank</td><td>money.n.02: money</td><td>interest.n.06: interest, interest_group</td></tr><tr><td>0.3778</td><td>bank.n.04: bank</td><td>money.n.01: money</td><td>interest.n.06: interest, interest_group</td></tr><tr><td>0.3667</td><td>bank.n.06: bank</td><td>money.n.03: money</td><td>interest.n.05: interest, stake</td></tr><tr><td>0.3651</td><td>bank.n.06: bank</td><td>money.n.02: money</td><td>interest.n.06: interest, interest_group</td></tr><tr><td>0.3611</td><td>depository_financial_institution.n.01: depository_financial_institution, bank, banking_concern, banking_company</td><td>money.n.01: money</td><td>interest.n.06: interest, interest_group</td></tr><tr><td>0.3611</td><td>depository_financial_institution.n.01: depository_financial_institution, bank, banking_concern, banking_company</td><td>money.n.02: money</td><td>interest.n.06: interest, interest_group</td></tr><tr><td>0.3576</td><td>bank.n.04: bank</td><td>money.n.03: money</td><td>interest.n.06: interest, interest_group</td></tr><tr><td>0.3436</td><td>depository_financial_institution.n.01: depository_financial_institution, bank, banking_concern, banking_company</td><td>money.n.03: money</td><td>interest.n.06: interest, interest_group</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong>And the winner is</strong>, with a score of 0.4857142857142857:<ul>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<li><strong>bank.n.06</strong>: the funds held by a gambling house or the dealer in some gambling games</li>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<li><strong>money.n.02</strong>: wealth reckoned in terms of money</li>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<li><strong>interest.n.05</strong>: (law) a right or legal share of something; a financial involvement with something</li>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "</ul>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentence_options = [wordnet.synsets(word, pos=pos) for word, pos in sentence]\n",
    "\n",
    "import itertools\n",
    "all_combinations = list(itertools.product(*sentence_options))\n",
    "display(HTML(\"There are {} possible combinations!!\".format(len(all_combinations))))\n",
    "\n",
    "data = {}\n",
    "for comb in all_combinations:\n",
    "    sim = 0\n",
    "    for pair in itertools.combinations(comb, r=2):\n",
    "        if pair[0].pos() == pair[1].pos():  # WordNet does not return similarity between different part-of-speech\n",
    "            sim += wordnet.path_similarity(pair[0], pair[1])\n",
    "    data[comb] = sim\n",
    "\n",
    "import operator\n",
    "sorted_data = sorted(data.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "# Keep just the first 10\n",
    "display(HTML(\"Top 10 are:\"))\n",
    "top10 = sorted_data[:10]\n",
    "\n",
    "# Vamos a imprimir los lemmas, aunque un ordenador lo que querría son los synsets.\n",
    "data_to_display = []\n",
    "for it, sim in top10:\n",
    "    row = [\"{:0.4f}\".format(sim)]\n",
    "    for synset in it:\n",
    "        cell_text = \"{}: {}\".format(synset.name(), ', '.join([lema.name() for lema in synset.lemmas()]))\n",
    "        row.append(cell_text)\n",
    "    data_to_display.append(row)\n",
    "\n",
    "display_table(data_to_display, headers=[\"score\"] + [word for word, pos in sentence])\n",
    "\n",
    "# And the winner is\n",
    "winner, sim = top10[0]\n",
    "display(HTML(\"<strong>And the winner is</strong>, with a score of {}:<ul>\".format(sim)))\n",
    "for it in winner:\n",
    "    display(HTML(\"<li><strong>{}</strong>: {}</li>\".format(it.name(), it.definition())))\n",
    "display(HTML(\"</ul>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cómo podemos mejorar este resultado de manera fácil? Si tenemos información sobre el contexto, por ejemplo, si sabemos que es una noticia de la sección económica de un periódico, entonces podemos utilizar como input la frecuencia relativa de nuestros significados dentro de ese corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Especificidad y concreción\n",
    "\n",
    "¡Toma epígrage! Hay un método que te devuelve la profundidad en la jerarquía de conceptos de una palabra, ¿se podría evaluar en base a esto cómo de riguroso es un autor?\n",
    "\n",
    "En primer lugar, ten en cuenta que WordNet no es una estructura en forma de árbol, sino que es un grafo, es decir, ¡puede haber varios caminos para llegar a un mismo nodo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Path:\n",
      "entity.n.01 >> physical_entity.n.01 >> object.n.01 >> whole.n.02 >> living_thing.n.01 >> organism.n.01 >> animal.n.01 >> chordate.n.01 >> vertebrate.n.01 >> mammal.n.01 >> placental.n.01 >> carnivore.n.01 >> canine.n.02 >> dog.n.01\n",
      "== Path:\n",
      "entity.n.01 >> physical_entity.n.01 >> object.n.01 >> whole.n.02 >> living_thing.n.01 >> organism.n.01 >> animal.n.01 >> domestic_animal.n.01 >> dog.n.01\n"
     ]
    }
   ],
   "source": [
    "dog = wordnet.synset('dog.n.01')\n",
    "\n",
    "for path in dog.hypernym_paths():\n",
    "    print(\"== Path:\")\n",
    "    print(' >> '.join([item.name() for item in path]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto es importante porque al calcular la profundidad de un nodo en la jerarquía de conceptos obtendremos varios valores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table align=\"left\"><tr><th>synset</th><th>min_depth</th><th>max_depth</th></tr><tr><td>animal</td><td>6</td><td>6</td></tr><tr><td>dalmatian</td><td>6</td><td>9</td></tr><tr><td>dog</td><td>8</td><td>13</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = {'dog': 'dog.n.01',\n",
    "          'dalmatian': 'dalmatian.n.01',\n",
    "          'animal': 'animal.n.01'}\n",
    "\n",
    "data = []\n",
    "for w,s in words.items():\n",
    "    min_depth = wordnet.synset(s).min_depth()\n",
    "    max_depth = wordnet.synset(s).max_depth()\n",
    "    data.append([w, min_depth, max_depth])\n",
    "    \n",
    "display_table(data, [\"synset\", \"min_depth\", \"max_depth\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "es decir que si queremos comparar la profundidad relativa entre dos conceptos tenemos que procurar evaluar ambos **utilizando el mismo camino** para no obtener resultados indeseados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Referencias\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
